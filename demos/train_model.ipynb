{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b6ac26-bb08-49e9-a7c8-b74903bf52d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import psutil\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afb66b69-f5df-4ddb-9e8d-b909df4a40eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.2113603584\n",
      "209.7234714624\n"
     ]
    }
   ],
   "source": [
    "print(psutil.virtual_memory().used /1e10)\n",
    "print(psutil.virtual_memory().available / 1e10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "373be171-90f1-43b3-9ed3-9256962a4e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 195/195 [00:11<00:00, 17.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>abstract</th>\n",
       "      <th>abstract_embeddings</th>\n",
       "      <th>terms</th>\n",
       "      <th>relations</th>\n",
       "      <th>negatives</th>\n",
       "      <th>term_embeddings</th>\n",
       "      <th>pair_embeddings</th>\n",
       "      <th>negatives_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33383987</td>\n",
       "      <td>Temperature and Solvent Effects on H2 Splittin...</td>\n",
       "      <td>[-0.28345045, -0.54292804, 0.16380529, 0.15494...</td>\n",
       "      <td>[fold, lead, cooling, tetrahydrofuran, splitti...</td>\n",
       "      <td>[(individual, kinetic barrier), (lead, tetrahy...</td>\n",
       "      <td>[(fold, tetrahydrofuran), (cases, toluene), (e...</td>\n",
       "      <td>[[-0.28223613, -0.0036575377, 0.08042424, -0.1...</td>\n",
       "      <td>[([-0.7495256, 0.36571825, -0.84759635, -0.030...</td>\n",
       "      <td>[([-0.28223613, -0.0036575377, 0.08042424, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33383988</td>\n",
       "      <td>Mechanism for Rapid Conversion of Amines to Am...</td>\n",
       "      <td>[-0.2850943, -0.80024165, -0.11266672, 0.14250...</td>\n",
       "      <td>[Particle, Conversion, Amines, Ammonium Salts,...</td>\n",
       "      <td>[(Amines, Ammonium Salts)]</td>\n",
       "      <td>[(Particle, Rapid), (Conversion, Rapid), (Conv...</td>\n",
       "      <td>[[-0.5166602, 0.11687658, -0.09206407, -0.0107...</td>\n",
       "      <td>[([-0.34281886, 0.30733573, -0.13176091, 0.137...</td>\n",
       "      <td>[([-0.5166602, 0.11687658, -0.09206407, -0.010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33383989</td>\n",
       "      <td>Bisecting GlcNAc Protein N-Glycosylation Is Ch...</td>\n",
       "      <td>[-0.040046073, -1.0489765, -0.37665504, -0.493...</td>\n",
       "      <td>[Protein N-Glycosylation, Adipogenesis, Human,...</td>\n",
       "      <td>[(Adipogenesis, Human)]</td>\n",
       "      <td>[(Adipogenesis, Protein N-Glycosylation), (Cha...</td>\n",
       "      <td>[[-0.7968025, -0.20326202, -0.566039, -0.13663...</td>\n",
       "      <td>[([-0.21563068, 0.16044843, -0.39353308, -0.15...</td>\n",
       "      <td>[([-0.21563068, 0.16044843, -0.39353308, -0.15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33383992</td>\n",
       "      <td>Association of Exposure to Cattle with Self-Re...</td>\n",
       "      <td>[-0.310526, -0.5039563, 0.6601208, -0.08117764...</td>\n",
       "      <td>[relationship, human, study, bovine tuberculos...</td>\n",
       "      <td>[(health, human)]</td>\n",
       "      <td>[(health, relationship), (bovine tuberculosis,...</td>\n",
       "      <td>[[-0.25283906, 0.11320739, -0.30629858, -0.038...</td>\n",
       "      <td>[([0.006518982, 0.25178033, -0.0104505485, -0....</td>\n",
       "      <td>[([0.006518982, 0.25178033, -0.0104505485, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33383995</td>\n",
       "      <td>The Effect of Preoperative Video Based Pain Tr...</td>\n",
       "      <td>[0.091471456, -0.07006314, -0.11821665, -0.306...</td>\n",
       "      <td>[Analgesic, Control Group, Effect, Video, Pain...</td>\n",
       "      <td>[(Postoperative Pain, Total Knee Arthroplasty)...</td>\n",
       "      <td>[(Analgesic, Postoperative Pain), (Effect, Vid...</td>\n",
       "      <td>[[-0.51707596, 0.17515965, -0.48447058, -0.293...</td>\n",
       "      <td>[([-0.38955075, 0.314926, -0.6473092, -0.47112...</td>\n",
       "      <td>[([-0.51707596, 0.17515965, -0.48447058, -0.29...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                                           abstract  \\\n",
       "0  33383987  Temperature and Solvent Effects on H2 Splittin...   \n",
       "1  33383988  Mechanism for Rapid Conversion of Amines to Am...   \n",
       "2  33383989  Bisecting GlcNAc Protein N-Glycosylation Is Ch...   \n",
       "3  33383992  Association of Exposure to Cattle with Self-Re...   \n",
       "4  33383995  The Effect of Preoperative Video Based Pain Tr...   \n",
       "\n",
       "                                 abstract_embeddings  \\\n",
       "0  [-0.28345045, -0.54292804, 0.16380529, 0.15494...   \n",
       "1  [-0.2850943, -0.80024165, -0.11266672, 0.14250...   \n",
       "2  [-0.040046073, -1.0489765, -0.37665504, -0.493...   \n",
       "3  [-0.310526, -0.5039563, 0.6601208, -0.08117764...   \n",
       "4  [0.091471456, -0.07006314, -0.11821665, -0.306...   \n",
       "\n",
       "                                               terms  \\\n",
       "0  [fold, lead, cooling, tetrahydrofuran, splitti...   \n",
       "1  [Particle, Conversion, Amines, Ammonium Salts,...   \n",
       "2  [Protein N-Glycosylation, Adipogenesis, Human,...   \n",
       "3  [relationship, human, study, bovine tuberculos...   \n",
       "4  [Analgesic, Control Group, Effect, Video, Pain...   \n",
       "\n",
       "                                           relations  \\\n",
       "0  [(individual, kinetic barrier), (lead, tetrahy...   \n",
       "1                         [(Amines, Ammonium Salts)]   \n",
       "2                            [(Adipogenesis, Human)]   \n",
       "3                                  [(health, human)]   \n",
       "4  [(Postoperative Pain, Total Knee Arthroplasty)...   \n",
       "\n",
       "                                           negatives  \\\n",
       "0  [(fold, tetrahydrofuran), (cases, toluene), (e...   \n",
       "1  [(Particle, Rapid), (Conversion, Rapid), (Conv...   \n",
       "2  [(Adipogenesis, Protein N-Glycosylation), (Cha...   \n",
       "3  [(health, relationship), (bovine tuberculosis,...   \n",
       "4  [(Analgesic, Postoperative Pain), (Effect, Vid...   \n",
       "\n",
       "                                     term_embeddings  \\\n",
       "0  [[-0.28223613, -0.0036575377, 0.08042424, -0.1...   \n",
       "1  [[-0.5166602, 0.11687658, -0.09206407, -0.0107...   \n",
       "2  [[-0.7968025, -0.20326202, -0.566039, -0.13663...   \n",
       "3  [[-0.25283906, 0.11320739, -0.30629858, -0.038...   \n",
       "4  [[-0.51707596, 0.17515965, -0.48447058, -0.293...   \n",
       "\n",
       "                                     pair_embeddings  \\\n",
       "0  [([-0.7495256, 0.36571825, -0.84759635, -0.030...   \n",
       "1  [([-0.34281886, 0.30733573, -0.13176091, 0.137...   \n",
       "2  [([-0.21563068, 0.16044843, -0.39353308, -0.15...   \n",
       "3  [([0.006518982, 0.25178033, -0.0104505485, -0....   \n",
       "4  [([-0.38955075, 0.314926, -0.6473092, -0.47112...   \n",
       "\n",
       "                                negatives_embeddings  \n",
       "0  [([-0.28223613, -0.0036575377, 0.08042424, -0....  \n",
       "1  [([-0.5166602, 0.11687658, -0.09206407, -0.010...  \n",
       "2  [([-0.21563068, 0.16044843, -0.39353308, -0.15...  \n",
       "3  [([0.006518982, 0.25178033, -0.0104505485, -0....  \n",
       "4  [([-0.51707596, 0.17515965, -0.48447058, -0.29...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dir = '../data/60k_pmid_dataset_chunks_sentencewise_negatives'\n",
    "\n",
    "df_list = [pd.read_pickle(os.path.join(input_dir, f)) for f in tqdm(sorted(os.listdir(input_dir)))]\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b9a66b5-f78c-4967-9804-2461ba639fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194874"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd1d7189-4bd3-4481-a981-6654eaadd547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149625"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['negatives_embeddings'].apply(lambda x : len(x) > 10)]\n",
    "# df = df[df['pair_embeddings'].apply(lambda x: len(x) > 0)]\n",
    "# len(df[df['negatives_embeddings'].apply(lambda x: len(x) > 10)])\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "374388e6-4d7a-4169-95ca-8a927b34df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pmids, temp_pmids = train_test_split(pmids, test_size=0.2, random_state=42)\n",
    "test_pmids, val_pmids = train_test_split(temp_pmids, test_size=0.5, random_state=42)\n",
    "\n",
    "train_df = df[df['pmid'].isin(train_pmids)]\n",
    "test_df = df[df['pmid'].isin(test_pmids)]\n",
    "val_df = df[df['pmid'].isin(val_pmids)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38f7f917-586a-4423-afa9-7bbbc264f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationDataset(Dataset):\n",
    "    def __init__(self, df, num_negatives=10):\n",
    "        self.df = df\n",
    "        self.num_negatives = num_negatives\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        abstract_emb = torch.tensor(row['abstract_embeddings'], dtype=torch.float32)\n",
    "        \n",
    "        pos_pair, pos_embedding = random.choice(list(zip(row['relations'], row['pair_embeddings'])))\n",
    "        pos_sample = torch.cat([\n",
    "            abstract_emb, \n",
    "            torch.tensor(pos_embedding, dtype=torch.float32).flatten()\n",
    "        ])\n",
    "        pos_term1, pos_term2 = pos_pair\n",
    "\n",
    "        hard_negatives = []\n",
    "        used_pairs = set()\n",
    "\n",
    "        for neg_pair, neg_emb in zip(row['negatives'], row['negatives_embeddings']):\n",
    "            if (\n",
    "                (neg_pair[0] == pos_term1 or neg_pair[0] == pos_term2 or\n",
    "                neg_pair[1] == pos_term1 or neg_pair[1] == pos_term2)\n",
    "                and neg_pair != pos_pair\n",
    "            ):\n",
    "                hard_negatives.append(torch.cat([\n",
    "                    abstract_emb, \n",
    "                    torch.tensor(neg_emb, dtype=torch.float32).flatten()\n",
    "                ]))\n",
    "                used_pairs.add(tuple(neg_pair))\n",
    "\n",
    "            if len(hard_negatives) >= 10:\n",
    "                break\n",
    "\n",
    "        remaining_negatives = [\n",
    "            (neg_pair, neg_emb) for neg_pair, neg_emb in zip(row['negatives'], row['negatives_embeddings'])\n",
    "            if tuple(neg_pair) not in used_pairs and tuple(neg_pair) != tuple(pos_pair)\n",
    "        ]\n",
    "\n",
    "        additional_negs_needed = self.num_negatives - len(hard_negatives)\n",
    "\n",
    "        if additional_negs_needed > 0:\n",
    "            sampled_random = random.choices(remaining_negatives, k=additional_negs_needed)\n",
    "            hard_negatives += [\n",
    "                torch.cat([abstract_emb, torch.tensor(neg_emb, dtype=torch.float32).flatten()])\n",
    "                for _, neg_emb in sampled_random\n",
    "            ]\n",
    "\n",
    "        X = torch.stack([pos_sample] + hard_negatives)\n",
    "        y = torch.tensor([1] + [0]*self.num_negatives, dtype=torch.float32)\n",
    "\n",
    "        return X, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1e51c12-3d21-4711-969f-504bc2fd9cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    if len(batch) == 0:\n",
    "        return None, None\n",
    "    X, y = zip(*batch)\n",
    "    return torch.stack(X), torch.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a6f2391-f7f5-4f69-a022-2c254eb822ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RelationDataset(train_df)\n",
    "test_dataset = RelationDataset(test_df)\n",
    "val_dataset = RelationDataset(val_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78ed8bfd-0fe3-4f4f-b603-78f9a83fbb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pmid                                                             33481430\n",
       "abstract                Hypopigmentation in Extramammary Paget Disease...\n",
       "abstract_embeddings     [0.82409924, -0.7536595, 0.05372125, -0.839472...\n",
       "terms                   [Prognostic Factor, Important, Rate, High, Poo...\n",
       "relations                [(Extramammary Paget Disease, Hypopigmentation)]\n",
       "negatives               [(High, Outcome), (Prognostic Factor, Rate), (...\n",
       "term_embeddings         [[-0.29985824, 0.13411663, -0.0663986, -0.2757...\n",
       "pair_embeddings         [([-0.47598863, -0.030381847, -0.7351567, -0.6...\n",
       "negatives_embeddings    [([-0.22897896, 0.21014515, -0.063291, 0.04567...\n",
       "Name: 90191, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[19818]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a113c53-d6ef-45b9-ae0b-eb89bce364c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11, 2304]), torch.Size([11]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 19818\n",
    "train_dataset[i][0].shape, train_dataset[i][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dc7870d-f97c-4ae4-be27-a7c236eb3789",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.fc(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "479f4638-e031-46d2-a972-290f6fc21adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "input_dim = 2304\n",
    "model = RelationClassifier(input_dim)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "criterion = nn.MarginRankingLoss(margin=0.2, reduction='sum')\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "769cbea3-6d7f-4100-b87f-f34799fa5139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            pos_samples = X[y==1]\n",
    "            neg_samples = X[y==0]\n",
    "\n",
    "            pos_scores = model(pos_samples).squeeze()\n",
    "            neg_scores = model(neg_samples).squeeze()\n",
    "\n",
    "            if pos_scores.dim() == 0:\n",
    "                pos_scores = pos_scores.unsqueeze(0)\n",
    "\n",
    "            comb_scores = torch.cartesian_prod(pos_scores, neg_scores).to(device)\n",
    "\n",
    "            target = torch.ones(len(comb_scores), device=device)\n",
    "            loss = criterion(comb_scores[:,0], comb_scores[:,1], target)\n",
    "\n",
    "            total_loss += loss\n",
    "            all_scores.extend(pos_scores.tolist())\n",
    "            all_labels.extend([1]*len(pos_scores))\n",
    "            all_scores.extend(neg_scores.tolist())\n",
    "            all_labels.extend([0]*len(neg_scores))\n",
    "\n",
    "    roc_auc = roc_auc_score(all_labels, all_scores)\n",
    "    pr_auc = average_precision_score(all_labels, all_scores)\n",
    "\n",
    "    return total_loss / len(dataloader), roc_auc, pr_auc        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f6cea4a-8d8b-46ad-aa27-6b72cb6b003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pos_samples = X[y==1]\n",
    "        neg_samples = X[y==0]\n",
    "\n",
    "        pos_scores = model(pos_samples).squeeze()\n",
    "        neg_scores = model(neg_samples).squeeze()\n",
    "\n",
    "        if pos_scores.dim() == 0:\n",
    "            pos_scores = pos_scores.unsqueeze(0)\n",
    "            \n",
    "        comb_scores = torch.cartesian_prod(pos_scores, neg_scores).to(device)\n",
    "\n",
    "        target = torch.ones(len(comb_scores), device=device)\n",
    "        loss = criterion(comb_scores[:,0], comb_scores[:,1] , target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41c0ef79-4958-47bd-b775-9b4df5cf1a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:   0%|                                 | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/50]\n",
      "Training Loss: 5137.7473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:   2%|▍                      | 1/50 [01:23<1:08:14, 83.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4544.7280, ROC AUC: 0.7583, PR AUC: 0.2409\n",
      "Saving best current model state at epoch: 1\n",
      "\n",
      "Epoch [2/50]\n",
      "Training Loss: 4322.8659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:   4%|▉                      | 2/50 [02:47<1:06:52, 83.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4151.4082, ROC AUC: 0.7798, PR AUC: 0.2700\n",
      "Saving best current model state at epoch: 2\n",
      "\n",
      "Epoch [3/50]\n",
      "Training Loss: 3944.3195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:   6%|█▍                     | 3/50 [04:10<1:05:33, 83.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3967.4482, ROC AUC: 0.7910, PR AUC: 0.2880\n",
      "Saving best current model state at epoch: 3\n",
      "\n",
      "Epoch [4/50]\n",
      "Training Loss: 3637.8535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:   8%|█▊                     | 4/50 [05:34<1:04:06, 83.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3883.2493, ROC AUC: 0.7951, PR AUC: 0.2940\n",
      "Saving best current model state at epoch: 4\n",
      "\n",
      "Epoch [5/50]\n",
      "Training Loss: 3389.6401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  10%|██▎                    | 5/50 [06:57<1:02:29, 83.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3754.5022, ROC AUC: 0.8035, PR AUC: 0.3030\n",
      "Saving best current model state at epoch: 5\n",
      "\n",
      "Epoch [6/50]\n",
      "Training Loss: 3178.4571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  12%|██▊                    | 6/50 [08:20<1:01:10, 83.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3699.2463, ROC AUC: 0.8067, PR AUC: 0.3060\n",
      "Saving best current model state at epoch: 6\n",
      "\n",
      "Epoch [7/50]\n",
      "Training Loss: 2965.6802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  14%|███▌                     | 7/50 [09:44<59:47, 83.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3679.4312, ROC AUC: 0.8073, PR AUC: 0.3099\n",
      "Saving best current model state at epoch: 7\n",
      "\n",
      "Epoch [8/50]\n",
      "Training Loss: 2782.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  16%|████                     | 8/50 [11:07<58:25, 83.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3651.3008, ROC AUC: 0.8096, PR AUC: 0.3083\n",
      "Saving best current model state at epoch: 8\n",
      "\n",
      "Epoch [9/50]\n",
      "Training Loss: 2593.7267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  18%|████▌                    | 9/50 [12:31<57:10, 83.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3681.9390, ROC AUC: 0.8108, PR AUC: 0.3113\n",
      "Saving best current model state at epoch: 9\n",
      "\n",
      "Epoch [10/50]\n",
      "Training Loss: 2426.3282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  20%|████▊                   | 10/50 [13:55<55:47, 83.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3656.0688, ROC AUC: 0.8112, PR AUC: 0.3124\n",
      "Saving best current model state at epoch: 10\n",
      "\n",
      "Epoch [11/50]\n",
      "Training Loss: 2248.1289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  22%|█████▎                  | 11/50 [15:19<54:20, 83.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3746.4004, ROC AUC: 0.8100, PR AUC: 0.3047\n",
      "\n",
      "Epoch [12/50]\n",
      "Training Loss: 2086.8444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  24%|█████▊                  | 12/50 [16:42<52:51, 83.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3772.6135, ROC AUC: 0.8105, PR AUC: 0.3186\n",
      "\n",
      "Epoch [13/50]\n",
      "Training Loss: 1947.8735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  26%|██████▏                 | 13/50 [18:06<51:31, 83.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3804.5552, ROC AUC: 0.8108, PR AUC: 0.3163\n",
      "\n",
      "Epoch [14/50]\n",
      "Training Loss: 1800.2664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  28%|██████▋                 | 14/50 [19:29<50:05, 83.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3971.5264, ROC AUC: 0.8042, PR AUC: 0.3116\n",
      "\n",
      "Epoch [15/50]\n",
      "Training Loss: 1640.9357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  30%|███████▏                | 15/50 [20:52<48:39, 83.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3801.9587, ROC AUC: 0.8114, PR AUC: 0.3202\n",
      "Saving best current model state at epoch: 15\n",
      "\n",
      "Epoch [16/50]\n",
      "Training Loss: 1522.6089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  32%|███████▋                | 16/50 [22:16<47:17, 83.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4005.1917, ROC AUC: 0.8066, PR AUC: 0.3033\n",
      "\n",
      "Epoch [17/50]\n",
      "Training Loss: 1415.3376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  34%|████████▏               | 17/50 [23:39<45:53, 83.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4005.2571, ROC AUC: 0.8096, PR AUC: 0.3103\n",
      "\n",
      "Epoch [18/50]\n",
      "Training Loss: 1301.4743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  36%|████████▋               | 18/50 [25:02<44:29, 83.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4021.5867, ROC AUC: 0.8052, PR AUC: 0.3115\n",
      "\n",
      "Epoch [19/50]\n",
      "Training Loss: 1213.5364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  38%|█████████               | 19/50 [26:26<43:06, 83.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4038.6626, ROC AUC: 0.8075, PR AUC: 0.3075\n",
      "\n",
      "Epoch [20/50]\n",
      "Training Loss: 1119.6207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  40%|█████████▌              | 20/50 [27:49<41:39, 83.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4111.1538, ROC AUC: 0.8078, PR AUC: 0.3090\n",
      "\n",
      "Epoch [21/50]\n",
      "Training Loss: 1026.6409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  42%|██████████              | 21/50 [29:12<40:16, 83.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4126.9189, ROC AUC: 0.8098, PR AUC: 0.3091\n",
      "\n",
      "Epoch [22/50]\n",
      "Training Loss: 968.9470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  44%|██████████▌             | 22/50 [30:36<38:51, 83.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4326.8667, ROC AUC: 0.8034, PR AUC: 0.3090\n",
      "\n",
      "Epoch [23/50]\n",
      "Training Loss: 887.0327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  46%|███████████             | 23/50 [31:58<37:25, 83.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4289.6387, ROC AUC: 0.8043, PR AUC: 0.3010\n",
      "\n",
      "Epoch [24/50]\n",
      "Training Loss: 822.8012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  48%|███████████▌            | 24/50 [33:22<36:01, 83.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4290.9966, ROC AUC: 0.8040, PR AUC: 0.3060\n",
      "\n",
      "Epoch [25/50]\n",
      "Training Loss: 787.9953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch...:  48%|███████████▌            | 24/50 [34:44<37:38, 86.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4282.2412, ROC AUC: 0.8006, PR AUC: 0.2948\n",
      "Early stopping due to no improvement. Total training epochs: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "best_train_loss = 999999\n",
    "best_val_roc_auc = 0\n",
    "patience = 10\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Training epoch...\"):\n",
    "    print(f\"\\nEpoch [{epoch+1}/{num_epochs}]\")\n",
    "    \n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    val_loss, val_roc_auc, val_pr_auc = evaluate(model, val_loader, criterion, device)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, ROC AUC: {val_roc_auc:.4f}, PR AUC: {val_pr_auc:.4f}\")\n",
    "\n",
    "    if val_roc_auc > best_val_roc_auc:\n",
    "        best_val_roc_auc = val_roc_auc\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), '../models/60000_pmid_model_v4.pth')\n",
    "        print(f\"Saving best current model state at epoch: {epoch+1}\")\n",
    "        \n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping due to no improvement. Total training epochs: {epoch+1}\")\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a3a3caf-f663-456e-9f28-7f93aecbef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/60000_pmid_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d99650f-bde8-4a3d-bc53-fc67fac04430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.5394, ROC AUC: 0.9190, PR AUC: 0.2627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_roc_auc, test_pr_auc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, ROC AUC: {test_roc_auc:.4f}, PR AUC: {test_pr_auc:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b852ce2e-fc2c-4c1c-9f87-4b5a85e03c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4558, -0.8255,  0.2465,  ...,  0.0486,  0.4510,  0.7287],\n",
       "         [-0.4558, -0.8255,  0.2465,  ..., -0.4669,  0.2165,  0.2500],\n",
       "         [-0.4558, -0.8255,  0.2465,  ..., -0.2303,  0.1060,  0.1860],\n",
       "         ...,\n",
       "         [-0.4558, -0.8255,  0.2465,  ..., -0.2458,  0.1991,  0.2456],\n",
       "         [-0.4558, -0.8255,  0.2465,  ..., -0.2303,  0.1060,  0.1860],\n",
       "         [-0.4558, -0.8255,  0.2465,  ..., -0.0977, -0.6139,  0.4175]]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_dataset[1000][0]\n",
    "y = train_dataset[1000][1]\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7a0750c-d3ce-4d66-bba7-e48c6e895040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4558, -0.8255,  0.2465,  ...,  0.0486,  0.4510,  0.7287]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.4558, -0.8255,  0.2465,  ..., -0.4669,  0.2165,  0.2500],\n",
       "         [-0.4558, -0.8255,  0.2465,  ..., -0.2303,  0.1060,  0.1860],\n",
       "         [-0.4558, -0.8255,  0.2465,  ..., -0.0573, -0.0356,  0.3023],\n",
       "         ...,\n",
       "         [-0.4558, -0.8255,  0.2465,  ..., -0.2458,  0.1991,  0.2456],\n",
       "         [-0.4558, -0.8255,  0.2465,  ..., -0.2303,  0.1060,  0.1860],\n",
       "         [-0.4558, -0.8255,  0.2465,  ..., -0.0977, -0.6139,  0.4175]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_samples = X[y==1].to(device)\n",
    "neg_samples = X[y==0].to(device)\n",
    "pos_samples, neg_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38f15575-51d7-48a8-a39c-075a8aa2cc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2304])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9cdda2b5-6be0-4971-a84e-5e0d5834de0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7222, device='cuda:0', grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_scores = model(pos_samples).squeeze()\n",
    "pos_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69e75f9d-ec52-4263-a3e2-a12b13cbbe27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7222, device='cuda:0', grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_scores.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5a56181-34b4-4820-a94f-593b4137e03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.1359e-02, 7.0541e-01, 2.5924e-01, 6.1359e-02, 1.0361e-01, 3.9563e-13,\n",
       "        2.5813e-25, 6.1359e-02, 2.3524e-02, 6.4892e-01, 6.1359e-02, 2.5592e-01,\n",
       "        4.7449e-01, 6.7143e-03, 4.8653e-01, 5.5683e-02, 3.8976e-01, 8.7977e-02,\n",
       "        2.5924e-01, 1.4943e-01, 5.2637e-02, 1.6211e-11, 5.0831e-01, 2.4123e-01,\n",
       "        6.1359e-02, 9.3152e-02, 1.5495e-01, 6.1850e-01, 5.7529e-01, 6.1359e-02,\n",
       "        2.5313e-01, 2.4999e-01, 6.1359e-02, 1.6554e-04, 4.7209e-02, 1.0675e-01,\n",
       "        5.9973e-01, 1.2220e-02, 6.7506e-01, 6.1089e-01], device='cuda:0',\n",
       "       grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_scores = model(neg_samples).squeeze()\n",
    "neg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29ea18e7-9d72-4580-b554-2b2fa917d696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.2215e-01, 6.1359e-02],\n",
       "        [7.2215e-01, 7.0541e-01],\n",
       "        [7.2215e-01, 2.5924e-01],\n",
       "        [7.2215e-01, 6.1359e-02],\n",
       "        [7.2215e-01, 1.0361e-01],\n",
       "        [7.2215e-01, 3.9563e-13],\n",
       "        [7.2215e-01, 2.5813e-25],\n",
       "        [7.2215e-01, 6.1359e-02],\n",
       "        [7.2215e-01, 2.3524e-02],\n",
       "        [7.2215e-01, 6.4892e-01],\n",
       "        [7.2215e-01, 6.1359e-02],\n",
       "        [7.2215e-01, 2.5592e-01],\n",
       "        [7.2215e-01, 4.7449e-01],\n",
       "        [7.2215e-01, 6.7143e-03],\n",
       "        [7.2215e-01, 4.8653e-01],\n",
       "        [7.2215e-01, 5.5683e-02],\n",
       "        [7.2215e-01, 3.8976e-01],\n",
       "        [7.2215e-01, 8.7977e-02],\n",
       "        [7.2215e-01, 2.5924e-01],\n",
       "        [7.2215e-01, 1.4943e-01],\n",
       "        [7.2215e-01, 5.2637e-02],\n",
       "        [7.2215e-01, 1.6211e-11],\n",
       "        [7.2215e-01, 5.0831e-01],\n",
       "        [7.2215e-01, 2.4123e-01],\n",
       "        [7.2215e-01, 6.1359e-02],\n",
       "        [7.2215e-01, 9.3152e-02],\n",
       "        [7.2215e-01, 1.5495e-01],\n",
       "        [7.2215e-01, 6.1850e-01],\n",
       "        [7.2215e-01, 5.7529e-01],\n",
       "        [7.2215e-01, 6.1359e-02],\n",
       "        [7.2215e-01, 2.5313e-01],\n",
       "        [7.2215e-01, 2.4999e-01],\n",
       "        [7.2215e-01, 6.1359e-02],\n",
       "        [7.2215e-01, 1.6554e-04],\n",
       "        [7.2215e-01, 4.7209e-02],\n",
       "        [7.2215e-01, 1.0675e-01],\n",
       "        [7.2215e-01, 5.9973e-01],\n",
       "        [7.2215e-01, 1.2220e-02],\n",
       "        [7.2215e-01, 6.7506e-01],\n",
       "        [7.2215e-01, 6.1089e-01]], device='cuda:0', grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor = torch.cartesian_prod(pos_scores.unsqueeze(0), neg_scores).to(device)\n",
    "test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34fbd14d-c5b9-42dd-a98a-a597e4335cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.tensor([1]*len(test_tensor)).to(device)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8cd2783-43bc-4dfb-8d28-b22feadeda04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7787, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(test_tensor[:,0], test_tensor[:, 1], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "01e4869e-d51a-4383-bac2-bd826a11f4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5158, 0.5158, 0.5158, 0.5158, 0.5158, 0.5158, 0.5158, 0.5158, 0.5158,\n",
       "        0.5158, 0.5158, 0.5158, 0.5158, 0.5158, 0.5158, 0.5158, 0.5158, 0.5158,\n",
       "        0.5158, 0.5158, 0.5163, 0.5163, 0.5163, 0.5163, 0.5163, 0.5163, 0.5163,\n",
       "        0.5163, 0.5163, 0.5163, 0.5163, 0.5163, 0.5163, 0.5163, 0.5163, 0.5163,\n",
       "        0.5163, 0.5163, 0.5163, 0.5163, 0.5225, 0.5225, 0.5225, 0.5225, 0.5225,\n",
       "        0.5225, 0.5225, 0.5225, 0.5225, 0.5225, 0.5225, 0.5225, 0.5225, 0.5225,\n",
       "        0.5225, 0.5225, 0.5225, 0.5225, 0.5225, 0.5225], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "dc01b3da-71db-4e87-884e-e590f67aec7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5159, 0.5162, 0.5190, 0.5207, 0.5171, 0.5167, 0.5213, 0.5224, 0.5200,\n",
       "        0.5207, 0.5226, 0.5222, 0.5100, 0.5197, 0.5236, 0.5221, 0.5215, 0.5195,\n",
       "        0.5129, 0.5121, 0.5159, 0.5162, 0.5190, 0.5207, 0.5171, 0.5167, 0.5213,\n",
       "        0.5224, 0.5200, 0.5207, 0.5226, 0.5222, 0.5100, 0.5197, 0.5236, 0.5221,\n",
       "        0.5215, 0.5195, 0.5129, 0.5121, 0.5159, 0.5162, 0.5190, 0.5207, 0.5171,\n",
       "        0.5167, 0.5213, 0.5224, 0.5200, 0.5207, 0.5226, 0.5222, 0.5100, 0.5197,\n",
       "        0.5236, 0.5221, 0.5215, 0.5195, 0.5129, 0.5121], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4e116aec-acea-45d1-848f-6572ac1b26c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1001, device='cuda:0', grad_fn=<ClampMinBackward0>)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(test_tensor[0,0], test_tensor[0,1], torch.tensor(1).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a32153f5-1176-4661-87e9-7a816747906f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0971)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(torch.tensor(0.5158), torch.tensor(0.5129), torch.tensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6950ad-58ee-4d12-bddf-bf2526205655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
